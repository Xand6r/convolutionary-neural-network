{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ###########  implementation of a convnet on the cifar-10 dataset ############################################\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utilities import load_images\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=load_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weights_variable(shape):\n",
    "    weights=tf.truncated_normal(shape,stddev=0.1)\n",
    "    return tf.Variable(weights)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial=tf.constant(0.1,shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x,w):\n",
    "    return tf.nn.conv2d(x,w,strides=[1,1,1,1],padding=\"SAME\")\n",
    "\n",
    "def max_pool2x2(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "\n",
    "def conv_layer(inpu,shape):\n",
    "    weights=weights_variable(shape)\n",
    "    bias=bias_variable([shape[3]])\n",
    "    return tf.nn.relu(conv2d(inpu,weights)+bias)\n",
    "\n",
    "def full_layer(inp,size):\n",
    "    ln_size=int(inp.get_shape()[1])\n",
    "    weights=weights_variable([ln_size,size])\n",
    "    bias=bias_variable([size])\n",
    "    return tf.matmul(inp,weights)+bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1,c2,c3=30,50,80\n",
    "f1=500\n",
    "classification=tf.Graph()\n",
    "with classification.as_default():\n",
    "    with tf.name_scope(\"placeholders\"):\n",
    "        x=tf.placeholder(tf.float32,shape=(None,28*28))\n",
    "        y=tf.placeholder(tf.int32,shape=(None,))\n",
    "        drop=tf.placeholder(tf.float32)\n",
    "        \n",
    "    with tf.name_scope(\"transformation\"):\n",
    "        x_img=tf.reshape(x,[-1,28,28,1])\n",
    "        \n",
    "    with tf.name_scope(\"conv_1\"):\n",
    "        conv1_1=conv_layer(x_img,shape=[3,3,1,c1])\n",
    "        conv1_2=conv_layer(conv1_1,shape=[3,3,c1,c1])\n",
    "        conv1_3=conv_layer(conv1_2,shape=[3,3,c1,c1])\n",
    "        conv1_pool=max_pool2x2(conv1_1)\n",
    "        \n",
    "    with tf.name_scope(\"conv2\"):\n",
    "        conv2_1=conv_layer(conv1_pool,[3,3,c1,c2])\n",
    "        conv2_2=conv_layer(conv2_1,[3,3,c2,c2])\n",
    "        conv2_3=conv_layer(conv2_2,[3,3,c2,c2])\n",
    "        conv2_pool=max_pool2x2(conv2_1)\n",
    "        \n",
    "    with tf.name_scope(\"conv3\"):\n",
    "        conv3_1=conv_layer(conv2_pool,[3,3,c2,c3])\n",
    "        conv3_2=conv_layer(conv3_1,[3,3,c3,c3])\n",
    "        conv3_3=conv_layer(conv3_2,[3,3,c3,c3])\n",
    "        conv3_pool=tf.nn.max_pool(conv3_1,ksize=[1,7,7,1],strides=[1,7,7,1],padding=\"SAME\")\n",
    "        flat_out=tf.reshape(conv3_pool,[-1,c3])\n",
    "        \n",
    "    with tf.name_scope(\"hidden\"):\n",
    "        hidden1=tf.nn.dropout(full_layer(flat_out,f1),drop)\n",
    "        prediction=full_layer(hidden1,10)\n",
    "    \n",
    "    with tf.name_scope(\"train_step\"):\n",
    "        xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=prediction,labels=y)\n",
    "        train_loss=tf.reduce_mean(xentropy)\n",
    "        train_op=tf.train.AdamOptimizer(0.01).minimize(train_loss)\n",
    "        \n",
    "    with tf.name_scope(\"saver\"):\n",
    "        saver=tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset=data['data'].reshape(-1,28*28)\n",
    "x_train,x_test,y_train,y_test=train_test_split(dataset,data['targets'])\n",
    "x_train,x_test,y_train,y_test=np.array(x_train),np.array(x_test),np.array(y_train),np.array(y_test)\n",
    "\n",
    "def percent(rec,exp):\n",
    "    import sys\n",
    "    percent=str(round((rec/exp)*100,2))+\"%\"\n",
    "    sys.stdout.write(percent)\n",
    "    sys.stdout.write(\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /temp/tf_models/convolutions_temp.ckpt\n",
      "epoch0:0.3014345169067383\n",
      "epoch1:0.10703881084918976\n",
      "epoch2:0.11128994822502136\n",
      "epoch3:0.02442348562180996\n",
      "epoch4:0.014204118400812149\n",
      "epoch5:0.015037823468446732\n",
      "epoch6:0.014359831809997559\n",
      "epoch7:0.009290809743106365\n",
      "epoch8:0.008106707595288754\n",
      "epoch9:0.015886561945080757\n",
      "epoch10:0.010554688982665539\n",
      "epoch11:0.010190696455538273\n",
      "71.21%\r"
     ]
    }
   ],
   "source": [
    "n_epochs=20\n",
    "batch_size=1000\n",
    "N=x_train.shape[0]\n",
    "with classification.as_default():\n",
    "    with tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "        saver.restore(sess,r\"/temp/tf_models/convolutions_temp.ckpt\")\n",
    "        step=0\n",
    "        for epoch in range(n_epochs):\n",
    "#             print(\"epoch:{}\".format(epoch))\n",
    "            pos=0\n",
    "            while pos<N:\n",
    "                saver.save(sess,r\"/temp/tf_models/convolutions_temp.ckpt\")\n",
    "                percent(pos,N)\n",
    "                x_batch=x_train[pos:pos+batch_size]\n",
    "                y_batch=y_train[pos:pos+batch_size]\n",
    "                loss,_=sess.run([train_loss,train_op],feed_dict={x:x_batch,y:y_batch,drop:0.5})\n",
    "                pos+=batch_size\n",
    "            print(\"epoch{}:{}\".format(epoch,loss)) \n",
    "        print(\"done     \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /temp/tf_models/convolutions_temp.ckpt\n",
      "test_score 0.960478530229\n",
      "train_score 0.959766431674\n"
     ]
    }
   ],
   "source": [
    "train_batch=100\n",
    "with classification.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess,r\"/temp/tf_models/convolutions_temp.ckpt\")\n",
    "        for name,train,y in [[\"test_score\",x_test,y_test],[\"train_score\",x_train,y_train]]:\n",
    "            pos=0\n",
    "            out=[]\n",
    "            out=np.array(sess.run([prediction],feed_dict={x:train[pos:pos+train_batch],drop:1.})).reshape(-1,10)\n",
    "            while pos<train.shape[0]:\n",
    "                pos+=train_batch\n",
    "                temp=np.array(sess.run([prediction],feed_dict={x:train[pos:pos+train_batch],drop:1.})).reshape(-1,10) \n",
    "                out=np.vstack([out,temp])\n",
    "                percent(pos,train.shape[0])\n",
    "            print(name,np.array(np.argmax(out,1)==y).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /temp/tf_models/convolutions_temp.ckpt\n"
     ]
    }
   ],
   "source": [
    "with classification.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        saver.restore(sess,r\"/temp/tf_models/convolutions_temp.ckpt\")\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "        data=sess.run([prediction],feed_dict={x:x_train[:100],y:y_train[:10],drop:1.})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
